{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "import random\n",
    "from umap import UMAP\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import DBSCAN\n",
    "from collections import Counter\n",
    "import plotly.express as px\n",
    "import re\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_intro_outro_frames(df):\n",
    "    \"\"\"\n",
    "    Removes frames that are likely part of the introduction or outro based on the number of empty fields.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input dataframe containing frame data.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the cleaned dataframe and the removed frames.\n",
    "    \"\"\"\n",
    "    aux_df = df.copy()\n",
    "\n",
    "    # List to store the number of empty fields for each row\n",
    "    num_empty_fields = []\n",
    "    \n",
    "    # Iterate over each row in the dataframe\n",
    "    for index, row in aux_df.iterrows():\n",
    "        empty_fields = 0\n",
    "        # Count the number of empty fields in the current row\n",
    "        for field in row:\n",
    "            if len(field) == 0:\n",
    "                empty_fields += 1\n",
    "        num_empty_fields.append(empty_fields)\n",
    "    \n",
    "    # Convert the list to a numpy array for easier indexing\n",
    "    num_empty_fields = np.array(num_empty_fields)\n",
    "    \n",
    "    # Identify and separate the frames to be removed (those with more than 2 empty fields)\n",
    "    removed_frames = aux_df[num_empty_fields > 2]\n",
    "    \n",
    "    # Keep only the frames that have 2 or fewer empty fields\n",
    "    cleaned_df = aux_df[num_empty_fields <= 2]\n",
    "    \n",
    "    # Return the cleaned dataframe and the removed frames\n",
    "    return cleaned_df, removed_frames\n",
    "\n",
    "def clean_detections(df):\n",
    "    \"\"\"\n",
    "    Cleans the 'detections' column in the dataframe by selecting only persons with confidence > 0.5\n",
    "    and filtering out detections outside defined limits.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input dataframe containing detection data.\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: A series containing the cleaned detections.\n",
    "    \"\"\"\n",
    "    # Create a copy of the relevant columns\n",
    "    detections_df = df[['filename', 'detections']].copy()\n",
    "\n",
    "    # Initialize a list to store persons with confidence > 0.5\n",
    "    persons = []\n",
    "    \n",
    "    # Iterate over each detection in the dataframe\n",
    "    for detection in detections_df['detections']:\n",
    "        person_in_limits = []\n",
    "        for obj in detection:\n",
    "            if obj[4] == 'person' and obj[5] > 0.5:\n",
    "                person_in_limits.append(obj)\n",
    "        persons.append(person_in_limits)\n",
    "    \n",
    "    # Add the filtered persons to the dataframe\n",
    "    detections_df['persons'] = persons\n",
    "\n",
    "    # Further filter the persons to include only those within defined spatial limits\n",
    "    persons = []\n",
    "    for detection in detections_df['persons']:\n",
    "        person_in_limits = []\n",
    "        for obj in detection:\n",
    "            x, y, w, h = obj[0], obj[1], obj[2], obj[3]\n",
    "            x = x + w / 2\n",
    "            y = y + h / 2\n",
    "            if y < 525 and x > 125 and x < 1125 and w*h > 150000:\n",
    "                person_in_limits.append(obj)\n",
    "        persons.append(person_in_limits)\n",
    "    \n",
    "    # Update the dataframe with the filtered persons\n",
    "    detections_df['persons_in_limits'] = persons\n",
    "    \n",
    "    # Return the cleaned 'persons_in_limits' series\n",
    "    return detections_df['persons_in_limits']\n",
    "\n",
    "def clean_fer(df):\n",
    "    \"\"\"\n",
    "    Cleans the 'fer' column in the dataframe by filtering out faces outside defined limits\n",
    "    and removing faces with an area below a specified threshold.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input dataframe containing FER (Facial Emotion Recognition) data.\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: A series containing the cleaned FER data.\n",
    "    \"\"\"\n",
    "    # Create a copy of the relevant columns\n",
    "    fer_df = df[['filename', 'fer']].copy()\n",
    "\n",
    "    # Initialize a list to store faces within defined spatial limits\n",
    "    faces = []\n",
    "    \n",
    "    # Iterate over each frame in the FER data\n",
    "    for frame in fer_df['fer']:\n",
    "        faces_in_limits = []\n",
    "        for face in frame:\n",
    "            location = face['location']\n",
    "            x1, x2, y1, y2 = location[0], location[1], location[2], location[3]\n",
    "            x = (x1 + x2) / 2\n",
    "            y = (y1 + y2) / 2\n",
    "            if y < 470 and x > 125 and x < 1125:\n",
    "                faces_in_limits.append(face)\n",
    "        faces.append(faces_in_limits)\n",
    "    \n",
    "    # Add the filtered faces to the dataframe\n",
    "    fer_df['faces_in_limits'] = faces\n",
    "\n",
    "    # Define the area threshold for filtering faces\n",
    "    area_threshold = 25000\n",
    "    \n",
    "    # Initialize a list to store faces with area above the threshold\n",
    "    faces = []\n",
    "    \n",
    "    # Iterate over each frame in the 'faces_in_limits' data\n",
    "    for frame in fer_df['faces_in_limits']:\n",
    "        faces_above_area = []\n",
    "        for face in frame:\n",
    "            location = face['location']\n",
    "            x1, x2, y1, y2 = location[0], location[1], location[2], location[3]\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            area = w * h\n",
    "            if area > area_threshold:\n",
    "                faces_above_area.append(face)\n",
    "        faces.append(faces_above_area)\n",
    "    \n",
    "    # Update the dataframe with the filtered faces\n",
    "    fer_df['faces_in_limits_above_area'] = faces\n",
    "    \n",
    "    # Return the cleaned 'faces_in_limits_above_area' series\n",
    "    return fer_df['faces_in_limits_above_area']\n",
    "\n",
    "def clean_df(df):\n",
    "    \"\"\"\n",
    "    Cleans the input dataframe by removing outliers and cleaning specific columns.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input dataframe to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The cleaned dataframe.\n",
    "    \"\"\"\n",
    "    cleaned_df = df.copy()\n",
    "    cleaned_df, removed_frames= remove_intro_outro_frames(cleaned_df)\n",
    "    cleaned_df['detections'] = clean_detections(df)\n",
    "    cleaned_df['fer'] = clean_fer(df)\n",
    "    \n",
    "    return cleaned_df, removed_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_video(cleaned_df, video, print_results=True):\n",
    "    \"\"\"\n",
    "    Clusters the video frames into specific categories based on the number of persons and faces detected.\n",
    "\n",
    "    Parameters:\n",
    "    cleaned_df (pd.DataFrame): The cleaned dataframe containing frame data.\n",
    "    video (str): The video filename or identifier.\n",
    "    print_results (bool): Whether to print the clustering results. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary of 5 clusters with the corresponding dataframes.\n",
    "    \"\"\"\n",
    "    # Copy the cleaned dataframe\n",
    "    df = cleaned_df.copy()\n",
    "    \n",
    "    # Add columns to count the number of persons and faces in each frame\n",
    "    df['num_persons'] = df['detections'].apply(lambda x: len(x))\n",
    "    df['num_faces'] = df['fer'].apply(lambda x: len(x))\n",
    "    # First Clustering -> Divide the frames into 3 clusters (Split-view, 1-Person-View, Others)\n",
    "    \n",
    "    # Prepare the input for clustering using the 'num_persons' and 'num_faces' columns\n",
    "    input = df[['num_persons', 'num_faces']].values\n",
    "    std_input = StandardScaler().fit_transform(input)\n",
    "    if video == 'ad-ps':\n",
    "        pca = UMAP(n_neighbors=25, min_dist=0.1, n_components=2, metric='euclidean')\n",
    "    else:\n",
    "        pca = PCA()\n",
    "    reduced_data = pca.fit_transform(std_input)\n",
    "    #plot umap components\n",
    "    # Define the number of clusters and apply Agglomerative Clustering\n",
    "    n_clusters = 3\n",
    "    hc = AgglomerativeClustering(n_clusters=n_clusters, metric='euclidean', linkage='ward')\n",
    "    labels = hc.fit_predict(reduced_data)\n",
    "    #plot_cluster_data(reduced_data, labels, n_clusters=n_clusters, components=(0, 1, 2))\n",
    "    # Get the filenames of images for each cluster\n",
    "    cluster_img_indexes = []\n",
    "    for i in range(n_clusters):\n",
    "        cluster = []\n",
    "        cluster.append(df[labels == i]['filename'])\n",
    "        cluster_img_indexes.append(cluster)\n",
    "        \n",
    "    # Assign names to clusters and store the dataframes\n",
    "    first_cluster_data = assign_first_cluster_names_and_store_df(df, labels, n_clusters)\n",
    "    # Print the first clustering results if requested\n",
    "    if print_results:\n",
    "        print(\"First Clustering\")\n",
    "        for label, (cluster_name, cluster_df) in first_cluster_data.items():\n",
    "            print(f\"Cluster {label} is named: {cluster_name} and has {len(cluster_df)} frames.\")\n",
    "    \n",
    "    # Second Clustering -> Cluster the 1-Person-View into 3 clusters\n",
    "    \n",
    "    # Get the cluster with the name \"1-Person-View\"\n",
    "    for cluster in first_cluster_data:\n",
    "        if first_cluster_data[cluster][0] == \"1-Person-View\":\n",
    "            one_person_view = first_cluster_data[cluster][1]\n",
    "            break\n",
    "        \n",
    "    # Define the feature matrix for the second clustering\n",
    "    input_data = np.array(one_person_view['embedding'].values.tolist())\n",
    "    std_input = StandardScaler().fit_transform(input_data)\n",
    "    \n",
    "    # Apply UMAP\n",
    "    umap = UMAP(n_neighbors=15, min_dist=0.1, n_components=3, metric='euclidean')\n",
    "    reduced_data = umap.fit_transform(std_input)\n",
    "\n",
    "    # Apply Agglomerative Clustering for the second clustering\n",
    "    if video == 'ad-ps':\n",
    "        n_clusters = 5\n",
    "    else:\n",
    "        n_clusters = 3\n",
    "    hc = AgglomerativeClustering(n_clusters=n_clusters, metric='euclidean', linkage='ward')\n",
    "    labels = hc.fit_predict(reduced_data)\n",
    "    \n",
    "    # Get the filenames of images for each cluster in the second clustering\n",
    "    cluster_img_indexes = []\n",
    "    for i in range(n_clusters):\n",
    "        cluster = []\n",
    "        cluster.append(one_person_view[labels == i]['filename'])\n",
    "        cluster_img_indexes.append(cluster)\n",
    "        \n",
    "    # Assign names to the second clusters and store the dataframes\n",
    "    second_cluster_data = assign_second_cluster_names_and_store_df(one_person_view, labels, n_clusters)\n",
    "    \n",
    "    # Print the second clustering results if requested\n",
    "    if print_results:\n",
    "        print(\"Second Clustering\")\n",
    "        for label, (cluster_name, cluster_df) in second_cluster_data.items():\n",
    "            print(f\"Cluster {label} is named: {cluster_name} and has {len(cluster_df)} frames.\")\n",
    "            \n",
    "    # Combine all clusters into a single dictionary\n",
    "    all_clusters = {}\n",
    "    for i in range(3):\n",
    "        all_clusters[i] = first_cluster_data[i]\n",
    "    for i in range(n_clusters):\n",
    "        all_clusters[i+n_clusters] = second_cluster_data[i]\n",
    "        \n",
    "    # Remove the \"1-Person-View\" cluster as it's already divided\n",
    "    for cluster in all_clusters:\n",
    "        if all_clusters[cluster][0] == \"1-Person-View\":\n",
    "            del all_clusters[cluster]\n",
    "            break\n",
    "    # Reset the keys of the dictionary\n",
    "    all_clusters = dict(enumerate(all_clusters.values()))\n",
    "    \n",
    "    return all_clusters\n",
    "\n",
    "def assign_first_cluster_names_and_store_df(cleaned_df, labels, n_clusters):\n",
    "    \"\"\"\n",
    "    Assigns names to the first set of clusters based on the mean number of faces in each cluster and stores each cluster DataFrame along with its label.\n",
    "\n",
    "    Parameters:\n",
    "    cleaned_df (DataFrame): The dataframe containing the data.\n",
    "    y_hc (array-like): The cluster labels for each data point in the dataframe.\n",
    "    n_clusters (int): The number of clusters.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary mapping cluster labels to tuples containing the cluster name and DataFrame.\n",
    "    \"\"\"\n",
    "    # Create a list to store each cluster DataFrame along with its label\n",
    "    cluster_data = {}\n",
    "\n",
    "    # Create a list to store each cluster in a separate dataframe\n",
    "    clusters = []\n",
    "    for i in range(n_clusters):\n",
    "        cluster = cleaned_df[labels == i]\n",
    "        clusters.append(cluster)\n",
    "\n",
    "    # Calculate the mean of the number of persons and faces in each cluster\n",
    "    means = []\n",
    "    for cluster in clusters:\n",
    "        mean_num_persons = cluster['num_persons'].mean()\n",
    "        mean_num_faces = cluster['num_faces'].mean()\n",
    "        means.append((mean_num_persons, mean_num_faces))\n",
    "\n",
    "    # Print the means to verify the output\n",
    "    for mean in means:\n",
    "        print(mean)\n",
    "\n",
    "    # Assign names to the clusters based on the mean values\n",
    "    for i, mean in enumerate(means):\n",
    "        if round(mean[1]) == 2:\n",
    "            cluster_name = \"Split-view\"\n",
    "        elif round(mean[1]) == 1:\n",
    "            cluster_name = \"1-Person-View\"\n",
    "        else:\n",
    "            cluster_name = \"Others\"\n",
    "\n",
    "        # Store the cluster name and DataFrame\n",
    "        cluster_data[i] = (cluster_name, clusters[i])\n",
    "\n",
    "    return cluster_data\n",
    "\n",
    "def assign_second_cluster_names_and_store_df(one_person_view, labels, n_clusters):\n",
    "    \"\"\"\n",
    "    Assigns names to the second set of clusters based on the number of frames and stores each cluster DataFrame along with its label.\n",
    "\n",
    "    Parameters:\n",
    "    one_person_view (pd.DataFrame): The dataframe containing the \"1-Person-View\" cluster data.\n",
    "    labels (array-like): The cluster labels for each data point in the dataframe.\n",
    "    n_clusters (int): The number of clusters.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary mapping cluster labels to tuples containing the cluster name and DataFrame.\n",
    "    \"\"\"\n",
    "    # Create a list to store each cluster DataFrame along with its label\n",
    "    cluster_data = {}\n",
    "\n",
    "    # Create a list to store each cluster in a separate dataframe\n",
    "    clusters = []\n",
    "    for i in range(n_clusters):\n",
    "        cluster = one_person_view[labels == i]\n",
    "        clusters.append(cluster)\n",
    "\n",
    "    # Order the clusters by length and assign names (Person 1, Person 2, Person 3) based on the number of frames\n",
    "    clusters.sort(key=len, reverse=True)\n",
    "    \n",
    "    for i, cluster in enumerate(clusters):\n",
    "        if i == 0:\n",
    "            cluster_name = \"Person 1\"\n",
    "        elif i == 1:\n",
    "            cluster_name = \"Person 2\"\n",
    "        elif i == 2:\n",
    "            cluster_name = \"Person 3\"\n",
    "        elif i == 3:\n",
    "            cluster_name = \"Person 4\"\n",
    "        else:\n",
    "            cluster_name = \"Person 5\"\n",
    "\n",
    "        # Store the cluster name and DataFrame\n",
    "        cluster_data[i] = (cluster_name, clusters[i])\n",
    "        \n",
    "    return cluster_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labeling Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_df(all_clusters_dict, removed_frames):\n",
    "    \"\"\"\n",
    "    Labels the dataframe by assigning cluster IDs and labels to each frame, including the removed frames.\n",
    "\n",
    "    Parameters:\n",
    "    all_clusters_dict (dict): Dictionary of clusters containing dataframes.\n",
    "    removed_frames (pd.DataFrame): DataFrame of frames that were removed during cleaning.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The labeled dataframe with cluster IDs and labels.\n",
    "    \"\"\"\n",
    "    # Assign cluster ID and label to removed frames\n",
    "    removed_frames['cluster_id'] = -1\n",
    "    removed_frames['cluster_label'] = 'Removed Frame'\n",
    "    \n",
    "    # Assign cluster ID and label to each frame in the clusters\n",
    "    for cluster in all_clusters_dict:\n",
    "        all_clusters_dict[cluster][1].loc[:, 'cluster_id'] = cluster\n",
    "        all_clusters_dict[cluster][1].loc[:, 'cluster_label'] = all_clusters_dict[cluster][0]\n",
    "    \n",
    "    # Concatenate all cluster dataframes and sort them by filename\n",
    "    labeled_df = pd.concat([cluster[1] for cluster in all_clusters_dict.values()])\n",
    "    labeled_df = pd.concat([labeled_df, removed_frames])\n",
    "    labeled_df.sort_values('filename', inplace=True)\n",
    "    labeled_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    labeled_df = labeled_df[['filename', 'cluster_id', 'cluster_label'] + [col for col in labeled_df.columns if col not in ['filename','cluster_id', 'cluster_label', 'num_persons', 'num_faces']]]\n",
    "    \n",
    "    return labeled_df\n",
    "\n",
    "def label_moderator(labeled_df, video):\n",
    "    if video == 'ad-ps':\n",
    "        # Count the number of frames for each person\n",
    "        p1_len = len(labeled_df[labeled_df['cluster_label'] == \"Person 1\"])\n",
    "        p2_len = len(labeled_df[labeled_df['cluster_label'] == \"Person 2\"])\n",
    "        p3_len = len(labeled_df[labeled_df['cluster_label'] == \"Person 3\"])\n",
    "        p4_len = len(labeled_df[labeled_df['cluster_label'] == \"Person 4\"])\n",
    "        p5_len = len(labeled_df[labeled_df['cluster_label'] == \"Person 5\"])\n",
    "        \n",
    "        # Create a list of (person, length) tuples\n",
    "        clusters = [\n",
    "            (\"Person 1\", p1_len),\n",
    "            (\"Person 2\", p2_len),\n",
    "            (\"Person 3\", p3_len),\n",
    "            (\"Person 4\", p4_len),\n",
    "            (\"Person 5\", p5_len)\n",
    "        ]\n",
    "\n",
    "        # Sort the list by length in descending order\n",
    "        sorted_clusters = sorted(clusters, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Assign politic1 and politic2 to the two biggest clusters\n",
    "        politic1 = sorted_clusters[0][0]\n",
    "        politic2 = sorted_clusters[1][0]\n",
    "\n",
    "        # Extract labels for the 3 smallest clusters, excluding politic1 and politic2\n",
    "        smallest_clusters = sorted_clusters[2:]\n",
    "        available_labels = [cluster[0] for cluster in smallest_clusters]\n",
    "\n",
    "        # Shuffle the labels to randomize their assignment\n",
    "        random.shuffle(available_labels)\n",
    "\n",
    "        # Assign the randomized labels back to the smallest clusters\n",
    "        for i, cluster in enumerate(smallest_clusters):\n",
    "            smallest_clusters[i] = (cluster[0], cluster[1], available_labels[i])\n",
    "\n",
    "        # Unpack the updated smallest_clusters\n",
    "        moderator1 = smallest_clusters[0][2]\n",
    "        moderator2 = smallest_clusters[1][2]\n",
    "        moderator3 = smallest_clusters[2][2]\n",
    "        \n",
    "        # Update the labels in the original DataFrame\n",
    "        labeled_df.loc[labeled_df['cluster_label'] == moderator1, 'cluster_label'] = 'Moderator1'\n",
    "        labeled_df.loc[labeled_df['cluster_label'] == moderator2, 'cluster_label'] = 'Moderator2'\n",
    "        labeled_df.loc[labeled_df['cluster_label'] == moderator3, 'cluster_label'] = 'Moderator3'\n",
    "        labeled_df.loc[labeled_df['cluster_label'] == politic1, 'cluster_label'] = 'Politic 1'\n",
    "        labeled_df.loc[labeled_df['cluster_label'] == politic2, 'cluster_label'] = 'Politic 2'\n",
    "    else:\n",
    "        # Count the number of frames for each person\n",
    "        p1_len = len(labeled_df[labeled_df['cluster_label'] == \"Person 1\"])\n",
    "        p2_len = len(labeled_df[labeled_df['cluster_label'] == \"Person 2\"])\n",
    "        p3_len = len(labeled_df[labeled_df['cluster_label'] == \"Person 3\"])\n",
    "        \n",
    "        \n",
    "        # Create a list of (person, length) tuples\n",
    "        clusters = [\n",
    "            (\"Person 1\", p1_len),\n",
    "            (\"Person 2\", p2_len),\n",
    "            (\"Person 3\", p3_len)\n",
    "        ]\n",
    "        \n",
    "        sorted_clusters = sorted(clusters, key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        politic1 = sorted_clusters[0][0]\n",
    "        politic2 = sorted_clusters[1][0]\n",
    "        moderator = sorted(clusters, key=lambda x: x[1])[0][0]\n",
    "        \n",
    "        # Update the labels in the original DataFrame\n",
    "        labeled_df.loc[labeled_df['cluster_label'] == moderator, 'cluster_label'] = 'Moderator'\n",
    "        labeled_df.loc[labeled_df['cluster_label'] == politic1, 'cluster_label'] = 'Politic 1'\n",
    "        labeled_df.loc[labeled_df['cluster_label'] == politic2, 'cluster_label'] = 'Politic 2'\n",
    "    \n",
    "    return labeled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video Segmenting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_video(labeled_df, window_size=21):\n",
    "    # Format the dataframe\n",
    "    df = labeled_df.copy()\n",
    "    df = df.drop(['detections', 'poses', 'faces', 'text', 'embedding'], axis=1)\n",
    "    df['file_number'] = df['filename'].apply(extract_number) - 1\n",
    "    cluster_dict = get_video_labels(df)\n",
    "\n",
    "    # Apply the sliding window approach to smooth the cluster labels to get a more accurate video segmenting process\n",
    "    df['smoothed_cluster'] = df['cluster_id'].rolling(window_size, center=True).apply(lambda x: stats.mode(x)[0])\n",
    "    df['smoothed_cluster_label'] = df['smoothed_cluster'].map(cluster_dict)\n",
    "    df['smoothed_cluster_label'] = df['smoothed_cluster_label'].fillna(df['cluster_label'])\n",
    "    df['smoothed_cluster'] = df['smoothed_cluster'].fillna(df['cluster_id'])\n",
    "    \n",
    "    # Get the time segments for each of the cluster labels\n",
    "    df['cluster_change'] = (df['smoothed_cluster_label'] != df['smoothed_cluster_label'].shift()).cumsum()\n",
    "    df['emotion'] = df['fer'].apply(lambda x: x[0]['emotion'] if isinstance(x, list) and x else None)\n",
    "\n",
    "    # Group by cluster change and extract emotions for each segment\n",
    "    file_intervals = df.groupby('cluster_change').agg({'file_number': ['min', 'max'], 'emotion': lambda x: x.tolist()})\n",
    "    file_intervals.columns = ['min', 'max', 'emotions']\n",
    "\n",
    "    # Create a new dataframe with timeline exclusive data\n",
    "    smoothed_timeline_df = pd.DataFrame()\n",
    "    smoothed_timeline_df['start(s)'] = file_intervals['min'].astype(int)\n",
    "    smoothed_timeline_df['end(s)'] = file_intervals['max'].astype(int)\n",
    "    smoothed_timeline_df['start(hour)'] = pd.to_datetime(smoothed_timeline_df['start(s)'].apply(lambda x: '{:02d}:{:02d}:{:02d}'.format(x // 3600, x % 3600 // 60, x % 3600 % 60)), format='%H:%M:%S')\n",
    "    smoothed_timeline_df['end(hour)'] = pd.to_datetime(smoothed_timeline_df['end(s)'].apply(lambda x: '{:02d}:{:02d}:{:02d}'.format(x // 3600, x % 3600 // 60, x % 3600 % 60)), format='%H:%M:%S')\n",
    "    smoothed_timeline_df['duration'] = smoothed_timeline_df['end(s)'] - smoothed_timeline_df['start(s)'] + 1\n",
    "    smoothed_timeline_df['emotions'] = smoothed_timeline_df.index.map(lambda x: file_intervals.loc[x, 'emotions'])\n",
    "    smoothed_timeline_df['major_emotion'] = smoothed_timeline_df['emotions'].apply(major_emotion)\n",
    "    \n",
    "    smoothed_timeline_df = smoothed_timeline_df.drop('emotions', axis=1)\n",
    "    # Assign the correct cluster ids and labels for each of the time segments\n",
    "    cluster_mapping = df.drop_duplicates('cluster_change').set_index('cluster_change')['smoothed_cluster_label'].to_dict()\n",
    "    cluster_id_mapping = df.drop_duplicates('cluster_change').set_index('cluster_change')['smoothed_cluster'].to_dict()\n",
    "    smoothed_timeline_df['cluster_id'] = smoothed_timeline_df.index.map(cluster_id_mapping)\n",
    "    smoothed_timeline_df['cluster_label'] = smoothed_timeline_df.index.map(cluster_mapping)\n",
    "    # Format the dataframe\n",
    "    smoothed_timeline_df = smoothed_timeline_df.drop([\"start(s)\", \"end(s)\"], axis=1)\n",
    "    smoothed_timeline_df = smoothed_timeline_df.reset_index(drop=True)\n",
    "    smoothed_timeline_df = smoothed_timeline_df.sort_values(by='start(hour)', ascending=True)\n",
    "\n",
    "    return smoothed_timeline_df\n",
    "\n",
    "def non_smooth_video(labeled_df):\n",
    "    # Format the dataframe\n",
    "    df = labeled_df.copy()\n",
    "    df = df.drop(['detections', 'poses', 'faces', 'text', 'embedding'], axis=1)\n",
    "    df['file_number'] = df['filename'].apply(extract_number) - 1\n",
    "\n",
    "    # Get the time segments for each of the cluster labels\n",
    "    df['cluster_change'] = (df['cluster_label'] != df['cluster_label'].shift()).cumsum()\n",
    "    df['emotion'] = df['fer'].apply(lambda x: x[0]['emotion'] if isinstance(x, list) and x else None)\n",
    "\n",
    "    # Group by cluster change and extract emotions for each segment\n",
    "    file_intervals = df.groupby('cluster_change').agg({'file_number': ['min', 'max'], 'emotion': lambda x: x.tolist()})\n",
    "    file_intervals.columns = ['min', 'max', 'emotions']\n",
    "\n",
    "    # Create a new dataframe with timeline exclusive data\n",
    "    timeline_df = pd.DataFrame()\n",
    "    timeline_df['start(s)'] = file_intervals['min'].astype(int)\n",
    "    timeline_df['end(s)'] = file_intervals['max'].astype(int)\n",
    "    timeline_df['start(hour)'] = pd.to_datetime(timeline_df['start(s)'].apply(lambda x: '{:02d}:{:02d}:{:02d}'.format(x // 3600, x % 3600 // 60, x % 3600 % 60)), format='%H:%M:%S')\n",
    "    timeline_df['end(hour)'] = pd.to_datetime(timeline_df['end(s)'].apply(lambda x: '{:02d}:{:02d}:{:02d}'.format(x // 3600, x % 3600 // 60, x % 3600 % 60)), format='%H:%M:%S')\n",
    "    timeline_df['duration'] = timeline_df['end(s)'] - timeline_df['start(s)'] + 1\n",
    "    timeline_df['emotions'] = timeline_df.index.map(lambda x: file_intervals.loc[x, 'emotions'])\n",
    "    timeline_df['major_emotion'] = timeline_df['emotions'].apply(major_emotion)\n",
    "    timeline_df = timeline_df.drop('emotions', axis=1)\n",
    "    \n",
    "    # Assign the correct cluster ids and labels for each of the time segments\n",
    "    cluster_mapping = df.drop_duplicates('cluster_change').set_index('cluster_change')['cluster_label'].to_dict()\n",
    "    cluster_id_mapping = df.drop_duplicates('cluster_change').set_index('cluster_change')['cluster_id'].to_dict()\n",
    "    timeline_df['cluster_id'] = timeline_df.index.map(cluster_id_mapping)\n",
    "    timeline_df['cluster_label'] = timeline_df.index.map(cluster_mapping)\n",
    "    \n",
    "    # Format the dataframe\n",
    "    timeline_df = timeline_df.drop([\"start(s)\", \"end(s)\"], axis=1)\n",
    "    timeline_df = timeline_df.reset_index(drop=True)\n",
    "    timeline_df = timeline_df.sort_values(by='start(hour)', ascending=True)\n",
    "    \n",
    "    return timeline_df\n",
    "\n",
    "def segment_video_timeline_emotion(labeled_df):\n",
    "    \"\"\"\n",
    "    Segments the video timeline based on the emotion detected in each frame.\n",
    "    \n",
    "    Parameters:\n",
    "    \"\"\"\n",
    "    smoothed_timeline_df = smooth_video(labeled_df, window_size=31)\n",
    "    timeline_df = non_smooth_video(labeled_df)\n",
    "    \n",
    "    return smoothed_timeline_df, timeline_df\n",
    "\n",
    "def major_emotion(emotions_list):\n",
    "    # Count the occurrences of each emotion\n",
    "    emotion_counts = Counter(emotions_list)\n",
    "    \n",
    "    # Find the emotion with the highest count\n",
    "    major_emotion = max(emotion_counts, key=emotion_counts.get)\n",
    "    \n",
    "    \n",
    "    return major_emotion\n",
    "\n",
    "def extract_number(s):\n",
    "    \"\"\"\n",
    "        Description: This function extracts the number from a string\n",
    "        \n",
    "        input: s -> string\n",
    "        output: int -> number extracted from the string\n",
    "    \"\"\"    \n",
    "    return int(re.search(r'\\d+', s).group())  \n",
    "  \n",
    "def get_video_labels(df):\n",
    "    \"\"\"\n",
    "        Description: This function gets the video labels\n",
    "        \n",
    "        input: df -> dataframe with the following columns: cluster_id, cluster_label\n",
    "        output: cluster_dict -> dictionary with the cluster_id as key and the cluster_label as value\n",
    "    \"\"\"    \n",
    "    unique_df = df.drop_duplicates(subset=['cluster_id', 'cluster_label'])\n",
    "    cluster_dict = unique_df.set_index('cluster_id')['cluster_label'].to_dict()\n",
    "    \n",
    "    return dict(sorted(cluster_dict.items()))\n",
    "\n",
    "def get_total_screen_time(timeline_df):\n",
    "    \"\"\"\n",
    "        Description: This function gets the total screen time for each cluster\n",
    "        \n",
    "        input: timeline_df -> dataframe with the following columns: start(min), end(min), duration, cluster_id, cluster_label; ordered by start(min)\n",
    "        output: total_screen_time_df -> dataframe with the following columns: cluster_label, duration, duration(min)\n",
    "    \"\"\"\n",
    "    total_screen_time = timeline_df.groupby('cluster_label')['duration'].sum()\n",
    "    total_screen_time_df = total_screen_time.reset_index()\n",
    "    total_screen_time_df['duration(hour)'] = total_screen_time_df['duration'].apply(lambda x: '{:02d}:{:02d}:{:02d}'.format(x // 3600, x % 3600//60, x % 3600%60))\n",
    "    return total_screen_time_df\n",
    "\n",
    "def get_total_time_by_emotion(timeline_df):\n",
    "    # Group by cluster_label and emotion, and sum the durations\n",
    "    total_time_by_emotion = timeline_df.groupby(['cluster_label', 'major_emotion'])['duration'].sum().reset_index()\n",
    "    \n",
    "    # Pivot the table to have total time for each emotion in each cluster\n",
    "    total_time_by_emotion_pivot = total_time_by_emotion.pivot(index='cluster_label', columns='major_emotion', values='duration').fillna(0)\n",
    "    \n",
    "    # Calculate total duration for each cluster\n",
    "    total_duration_by_cluster = timeline_df.groupby('cluster_label')['duration'].sum().reset_index()\n",
    "    total_duration_by_cluster['total_duration(hour)'] = total_duration_by_cluster['duration'].apply(lambda x: '{:02d}:{:02d}:{:02d}'.format(x // 3600, x % 3600 // 60, x % 3600 % 60))\n",
    "    total_duration_by_cluster = total_duration_by_cluster.drop('duration', axis=1)\n",
    "    \n",
    "    # Merge total time by emotion and total duration by cluster\n",
    "    combined_df = pd.merge(total_time_by_emotion_pivot, total_duration_by_cluster, on='cluster_label', how='left')\n",
    "    \n",
    "    # Convert durations to 'hh:mm' format\n",
    "    for emotion in total_time_by_emotion_pivot.columns:\n",
    "        combined_df[f\"{emotion}(hour)\"] = combined_df[emotion].apply(lambda x: '{:02d}:{:02d}:{:02d}'.format(int(x) // 3600, int(x) % 3600 // 60, int(x) % 3600 % 60) if not pd.isnull(x) else '00:00:00')\n",
    "        \n",
    "        combined_df = combined_df.drop(emotion, axis=1)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_colors = {\n",
    "    'Neutral': '#D3D3D3',   # Light grey\n",
    "    'Happiness': '#FFD700',  # Gold\n",
    "    'Sadness': '#87CEEB',    # Sky blue\n",
    "    'Surprise': '#FFA500',   # Orange\n",
    "    'Fear': '#BA55D3',       # Medium purple\n",
    "    'Disgust': '#98FB98',    # Pale green\n",
    "    'Anger': '#FF6347',      # Tomato\n",
    "    'Contempt': '#BC8F8F',    # Rosy brown\n",
    "    'None': '#000000'        # Black\n",
    "}\n",
    "\n",
    "def plot_cluster_data(reduced_data, label_vector, n_clusters, components=(0, 1, 2)):\n",
    "    \"\"\"\n",
    "    Visualize 2D and 3D scatter plots for the given clustering results.\n",
    "    \n",
    "    Parameters:\n",
    "    reduced_data (np.array): The reduced data in 2D or 3D.\n",
    "    label_vector (np.array): The cluster labels for each data point.\n",
    "    n_clusters (int): The number of clusters.\n",
    "    components (tuple): The indices of the components to plot. Defaults to (0, 1, 2).\n",
    "    \"\"\"\n",
    "    # Create a DataFrame from the data for easier plotting with Plotly Express\n",
    "    df = pd.DataFrame(reduced_data, columns=[f'Principal Component {i+1}' for i in range(reduced_data.shape[1])])\n",
    "    df['Cluster'] = label_vector\n",
    "    df['Cluster Size'] = df.groupby('Cluster')['Cluster'].transform('size')\n",
    "\n",
    "    # 2D Scatter Plot\n",
    "    fig = px.scatter(df, x=f'Principal Component {components[0]+1}', y=f'Principal Component {components[1]+1}', color='Cluster', color_continuous_scale='Viridis', size='Cluster Size')\n",
    "    fig.update_layout(title='PCA 1st Round clustering', width=700, height=500, xaxis=dict(title=dict(text='Number of Persons', font=dict(size=16))), yaxis=dict(title=dict(text='Number of Faces', font=dict(size=16))))\n",
    "    fig.show()\n",
    "\n",
    "    # 3D Scatter Plot\n",
    "    if reduced_data.shape[1] >= 3 and len(components) >= 3:\n",
    "        fig = px.scatter_3d(df, x=f'Principal Component {components[0]+1}', y=f'Principal Component {components[1]+1}', z=f'Principal Component {components[2]+1}', color='Cluster', color_continuous_scale='Viridis', size='Cluster Size')\n",
    "        fig.update_layout(title='Clusters of customers (3D)')\n",
    "        fig.show()\n",
    "\n",
    "def visualize_labeled_df(labeled_df, video, images_per_cluster=10, images_per_row=10):\n",
    "    \"\"\"\n",
    "    Visualizes the labeled dataframe by displaying sample images from each cluster.\n",
    "\n",
    "    Parameters:\n",
    "    labeled_df (pd.DataFrame): The labeled dataframe containing cluster information.\n",
    "    images_per_cluster (int): Number of images to display per cluster. Defaults to 10.\n",
    "    images_per_row (int): Number of images to display per row. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    for cluster in labeled_df['cluster_id'].sort_values().unique():\n",
    "        # Print the cluster details\n",
    "        print(f\"Cluster {cluster} ({labeled_df[labeled_df['cluster_id'] == cluster]['cluster_label'].iloc[0]}) -> size: {len(labeled_df[labeled_df['cluster_id'] == cluster])} frames\")\n",
    "        \n",
    "        # Get the filenames of images for the current cluster\n",
    "        cluster_data = labeled_df[labeled_df['cluster_id'] == cluster]['filename'].values[:images_per_cluster]\n",
    "        num_images = len(cluster_data)\n",
    "        \n",
    "        # Calculate the number of rows required for displaying images\n",
    "        num_rows = (num_images + images_per_row - 1) // images_per_row\n",
    "        fig, axes = plt.subplots(num_rows, images_per_row, figsize=(20, 2 * num_rows))\n",
    "        axes = axes.ravel()\n",
    "        \n",
    "        # Display each image in the subplot\n",
    "        for i, img_path in enumerate(cluster_data):\n",
    "            img = Image.open(os.path.join(current_dir, 'processed', video, img_path))\n",
    "            ax = axes[i]\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "            ax.set_title(img_path)\n",
    "        \n",
    "        # Hide any remaining subplot axes\n",
    "        for j in range(num_images, num_rows * images_per_row):\n",
    "            axes[j].axis('off')\n",
    "            \n",
    "        # Adjust the layout and display the plot\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def plot_total_time_by_emotion(total_time_by_emotion_df):\n",
    "    total_time_by_emotion_df['start'] = pd.to_datetime('00:00:00', format='%H:%M:%S')\n",
    "    total_time_by_emotion_df = total_time_by_emotion_df.sort_values(by='cluster_label')\n",
    "    \n",
    "    fig = px.timeline(total_time_by_emotion_df, x_start='start', x_end='total_duration(hour)', y='cluster_label', \n",
    "                      color='major_emotion', color_discrete_map=emotion_colors, \n",
    "                      title='Total Time by Emotion per Cluster')\n",
    "    \n",
    "    fig.update_layout(yaxis={'categoryorder': 'total ascending'})\n",
    "    fig.update_yaxes(title_text='Cluster Label')\n",
    "    fig.update_xaxes(title_text='Total Duration (hour)')\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "def plot_timeline_w_major_emotion(timeline_df,video):\n",
    "    timeline_df = timeline_df.sort_values(by='cluster_label')\n",
    "    fig = px.timeline(timeline_df, x_start='start(hour)', x_end='end(hour)', y='cluster_label', \n",
    "                      color='major_emotion', color_discrete_map=emotion_colors, \n",
    "                      title='Video Timeline - '+ video)\n",
    "    fig.show()\n",
    "\n",
    "def plot_timeline(timeline_df):\n",
    "    \"\"\"\n",
    "        Description: This function plots the video timeline\n",
    "        \n",
    "        input: timeline_df -> dataframe with the following columns: start(min), end(min), duration, cluster_id, cluster_label; ordered by start(min)\n",
    "    \"\"\"\n",
    "    timeline_df = timeline_df.sort_values(by='cluster_label')\n",
    "    fig = px.timeline(timeline_df, x_start='start(hour)', x_end='end(hour)', y='cluster_label', \n",
    "                      color='cluster_label', color_discrete_map=emotion_colors, \n",
    "                      title='Video Timeline')\n",
    "    fig.show()\n",
    "    \n",
    "def plot_total_screen_time(timeline_df,video):\n",
    "    \"\"\"\n",
    "        Description: This function plots the total screen time for each cluster\n",
    "        \n",
    "        input: timeline_df -> dataframe with the following columns: start(min), end(min), duration, cluster_id, cluster_label; ordered by start(min)\n",
    "    \"\"\"\n",
    "    total_screen_time = timeline_df.groupby('cluster_label')['duration'].sum()\n",
    "    total_screen_time_df = total_screen_time.reset_index()\n",
    "    total_screen_time_df['duration(hour)'] = pd.to_datetime(total_screen_time_df['duration'].apply(lambda x: '{:02d}:{:02d}:{:02d}'.format(x // 3600, x % 3600//60, x % 3600%60)), format='%H:%M:%S')\n",
    "    total_screen_time_df['start']= pd.to_datetime('00:00:00', format='%H:%M:%S')\n",
    "    total_screen_time_df.sort_values(by='cluster_label', inplace=True)\n",
    "    \n",
    "    fig = px.timeline(total_screen_time_df, x_start ='start', x_end='duration(hour)', y='cluster_label', \n",
    "                      color='cluster_label', color_discrete_map=None, \n",
    "                      title='Screen Time per Cluster - '+ video)\n",
    "    \n",
    "    fig.update_traces(marker=dict(color='#1a7277'))  # Set color for all bars\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Video Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video_pickel(video, current_dir):\n",
    "    data = pd.read_pickle(os.path.join(current_dir, 'processed', video + '.pkl'))\n",
    "    data.sort_values('filename', inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "video = 'chega-ps'\n",
    "# Read the video pickle file\n",
    "original_df = read_video_pickel(video, current_dir)\n",
    "\n",
    "# Clean the original dataframe using the clean_df function\n",
    "cleaned_df, removed_frames = clean_df(original_df)\n",
    "# Get dictionary of 5 clusters with the corresponding dataframes (Person 1, Person 2, Person 3, Split-view, Others)\n",
    "all_clusters_dict = cluster_video(cleaned_df, video, print_results=False) \n",
    "\n",
    "# Put all the dataframes in a single dataframe with cluster IDs and labels\n",
    "labeled_df = label_df(all_clusters_dict, removed_frames)\n",
    "labeled_df = label_moderator(labeled_df, video)\n",
    "\n",
    "smoothed_timeline_df, timeline_df = segment_video_timeline_emotion(labeled_df)\n",
    "\n",
    "plot_timeline_w_major_emotion(timeline_df,video)\n",
    "plot_total_screen_time(timeline_df,video)\n",
    "plot_timeline_w_major_emotion(smoothed_timeline_df,video)\n",
    "plot_total_screen_time(smoothed_timeline_df,video)\n",
    "\n",
    "# Visualize the results of the clustering\n",
    "visualize_labeled_df(labeled_df, video, images_per_cluster=10, images_per_row=10)\n",
    "\n",
    "if video == 'ad-ps':\n",
    "    clusters_order = ['Removed Frame', 'Split-view', 'Politic 1', 'Politic 2', 'Moderator1', 'Moderator2', 'Moderator3', 'Others']\n",
    "else:\n",
    "    clusters_order = ['Removed Frame', 'Split-view', 'Politic 1', 'Politic 2', 'Moderator', 'Others']\n",
    "#for cluster in clusters_order:\n",
    "#    print(f\"Cluster: {cluster} -> {len(labeled_df[labeled_df['cluster_label'] == cluster])} frames\")\n",
    "#print('*'*10)\n",
    "# Save the labeled dataframe to a pickle file\n",
    "#labeled_df.to_pickle(os.path.join(current_dir, 'labeled', video + '_labeled.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video_pickel(video, current_dir):\n",
    "    data = pd.read_pickle(os.path.join(current_dir, 'processed', video + '.pkl'))\n",
    "    data.sort_values('filename', inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "files = os.listdir('processed')\n",
    "videos = [f for f in files if f.endswith('.pkl')]\n",
    "video_titles = [f.split('.')[0] for f in videos]\n",
    "for video in video_titles:\n",
    "    print(f\"Processing video: {video}\")\n",
    "    # Read the video pickle file\n",
    "    original_df = read_video_pickel(video, current_dir)\n",
    "\n",
    "    # Clean the original dataframe using the clean_df function\n",
    "    cleaned_df, removed_frames = clean_df(original_df)\n",
    "    # Get dictionary of 5 clusters with the corresponding dataframes (Person 1, Person 2, Person 3, Split-view, Others)\n",
    "    all_clusters_dict = cluster_video(cleaned_df, video, print_results=False) \n",
    "\n",
    "    # Put all the dataframes in a single dataframe with cluster IDs and labels\n",
    "    labeled_df = label_df(all_clusters_dict, removed_frames)\n",
    "    labeled_df = label_moderator(labeled_df, video)\n",
    "\n",
    "    #smoothed_timeline_df, timeline_df = segment_video_timeline_emotion(labeled_df)\n",
    "\n",
    "    #plot_timeline_w_major_emotion(smoothed_timeline_df,video)\n",
    "    #plot_total_screen_time(timeline_df,video)\n",
    "    #plot_total_screen_time(smoothed_timeline_df,video)\n",
    "\n",
    "    # Visualize the results of the clustering\n",
    "    visualize_labeled_df(labeled_df, video, images_per_cluster=40, images_per_row=10)\n",
    "\n",
    "    #if video == 'ad-ps':\n",
    "    #    clusters_order = ['Removed Frame', 'Split-view', 'Politic 1', 'Politic 2', 'Moderator1', 'Moderator2', 'Moderator3', 'Others']\n",
    "    #else:\n",
    "    #    clusters_order = ['Removed Frame', 'Split-view', 'Politic 1', 'Politic 2', 'Moderator', 'Others']\n",
    "    #for cluster in clusters_order:\n",
    "    #    print(f\"Cluster: {cluster} -> {len(labeled_df[labeled_df['cluster_label'] == cluster])} frames\")\n",
    "    #print('*'*10)\n",
    "    # Save the labeled dataframe to a pickle file\n",
    "    labeled_df.to_pickle(os.path.join(current_dir, 'labeled', video + '_labeled.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
